# 数据集及标注
前面提到过模型要从数据中学习经验，来提示自身效果

把很多数据放在一起，以一种便于读取的形式表示，称为数据集，它是训练模型时不可缺少的一部分[^1]，数据集极大地影响着最终模型的效果

[^1]: 这是对联结主义人工智能而言，现在绝大多数模型都属于这一范畴

## 数量
越大的网络需要越多的数据量，否则不能完全发挥网络结构的潜力

在大语言模型时代，因为网络的参数不断在数量级上提升，对训练数据的需求量也大大增加，例如Llama3.1使用了超过了15万亿个词[^2]的文本

::: details 说明
插个题外话，以大模型现在的发展趋势，人类这几千年历史上写下的所有文本都不够作为训练语料的，接下来纯靠提升参数量来提升效果的方式很快就要行不通了
:::

[^2]: 此处应实为token，此处为了便于理解而写为词

根据经验，以我们识别装甲板用的目标检测模型为例，通常需要几千张图作为样本才能达到较好效果，若再添加则提升较缓慢（想象$y=\sqrt x$的函数图像），也有队伍将数据集扩充至四万多张

## 多样性
模型会从数据中学习到特征，但并非仅仅只是你想要它学到的，而是所有的特征，包括偏见等情况，如大语言模型、AI绘画模型等对白人对男性的倾向性都是因数据在统计学上的差异造成的

曾经听说过一个例子，要训练识别野生动物种类的模型，在野外拍了好多照片训练完成之后，再用新的照片测试发现效果不错，但在动物园里却发现识别率极低。研究原因，最后发现模型学习到的并非动物的种类，而是每种动物都生活在特定环境下，模型实际是识别不同的环境，所以在动物园中相同的环境下就失效了

数据集应尽量囊括所有可能的干扰因素下的数据，以较少此带来的影响

## 质量
> Garbage in, garbage out

数据集的质量直接决定模型训练的效果，精度、错误率等数据会产生极大的影响

数据集污染是极严重的情况，需要引起重视，否则消耗算力训练出来的模型将毫无用处

## 数据标注
又称“打标”，即给数据添加标注信息，如目标框、类别、标签等

::: info 说明
机器学习方法有监督学习、无监督学习、强化学习等，其中监督学习的数据集是需要标注的
:::

因为数据量大，这一步通常非常繁重，需要消耗大量的时间

也有一些方式可以使这一步骤变得更轻松，比如用现有的ai模型进行初步标注，然后人工进行校对和优化

一些需要大量数据的大公司会雇佣大量廉价劳动力来完成这个工作，即数据标注员

## 标注工具
推荐一些工具，不同工具各有特点优劣，请按需灵活运用，详细使用方法请自行查阅资料

[Make Sense](https://www.makesense.ai/)

[Labelme](https://www.labelme.io/)

[Label Studio](https://labelstud.io/)