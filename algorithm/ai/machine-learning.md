# 机器学习
## 什么是机器学习
> A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.[^1]

这是机器学习的一个很经典的定义，来自Tom Mitchell

只看关键词，就可以很容易理解：program improves with experience，可以从经验中提升自身性能的程序

## 机器学习 & 深度学习 & 人工智能

我们经常会从媒体报道及学术资料中看到机器学习、深度学习、人工智能三个不同的名词，但往往又不解释几者之间的关系

三者中，最先出现的概念是人工智能，它是于 1956 年由 John McCarthy 提出。当时，人们渴望设计出一种“能够执行人类智能特征任务的机器”

之后，研究人员构思出机器学习的概念，而机器学习的核心是寻求实现人工智能的方法。于是就出现了朴素贝叶斯、决策树学习、人工神经网络等众多机器学习方法。其中，人工神经网络是模拟大脑生物结构的一种算法

再到后来，就出现了深度学习

深度学习的关键在于建立具有更多神经元、更多层级的深度神经网络。我们发现，这种深度神经网络的学习效果在几乎所有任务上取得了极好的效果

关于这三个概念，还可以说，机器学习是实现人工智能的手段，而深度学习是机器学习中的一种特定方法

::: tip 提示
目前，我们通常所说的机器学习大致包含四大类：监督学习，英文为 Supervised Learning；无监督学习，英文为 Unsupervised Learning；半监督学习，英文为 Semi-supervised Learning；强化学习，英文为 Reinforcement Learning

其中监督学习最为常见
:::

**省流：深度学习属于机器学习，机器学习属于人工智能**

::: info 说明
机器学习是人工智能的主流，深度学习又是机器学习的主流，基本可以认为学习到的人工智能知识大多都是深度学习领域的
:::

## 机器学习的关键要素
### 数据
机器学习关键在于学习，那么就必定需要 **学习资料**

每个数据集由一个个样本（example, sample）组成，通常每个样本由一组称为特征的属性组成，机器学习模型会根据这些属性进行预测

例如处理图像数据时，每一张单独的照片即为一个样本，它的特征由每个像素数值的有序列表表示。 比如，200*200的彩色照片由200*200*3=120000个数值组成，其中的“3”对应于每个空间位置的红、绿、蓝通道的强度。再比如，对于一组医疗数据，给定一组标准的特征（如年龄、生命体征和诊断），此数据可以用来尝试预测患者是否会存活。

当每个样本的特征类别数量都是相同的时候，其特征向量是固定长度的，这个长度被称为数据的维数（dimensionality）。固定长度的特征向量是一个方便的属性，它可以用来量化学习大量样本。

然而，并不是所有的数据都可以用“固定长度”的向量表示。以图像数据为例，如果它们全部来自标准显微镜设备，那么“固定长度”是可取的； 但是如果图像数据来自互联网，它们很难具有相同的分辨率或形状。这时，将图像裁剪成标准尺寸是一种方法，但这种办法很局限，会丢失信息。此外，文本数据更不符合“固定长度”的要求。与传统机器学习方法相比，深度学习的一个主要优势是可以处理不同长度的数据

一般来说，拥有越多数据的时候，最终训练出来的模型效果越好。一些深度学习模型就算在小数据集上能够工作，但效果可能并不比传统方法高

请注意，仅仅拥有海量的数据是不够的，我们还需要正确的数据。如果数据中充满了错误，或者如果数据的特征不能预测任务目标，那么模型很可能无效（“Garbage in, garbage out.”）。一种常见的问题来自不均衡的数据集，比如在一个有关医疗的训练数据集中，某些人群没有样本表示。想象一下，假设我们想要训练一个皮肤癌识别模型，但它在训练数据集中从未见过黑色皮肤的人，这个模型就会顿时束手无策

再比如，如果用“过去的招聘决策数据”来训练一个筛选简历的模型，那么机器学习模型可能会无意中捕捉到历史残留的不公正。然而，这一切都在开发者不知情的情况下发生，因此当数据不具有充分代表性，甚至包含了一些社会偏见时，模型就很有可能有偏见

### 目标函数
前面的内容将机器学习总结为“从经验中学习”。这里所说的“学习”，是指提高模型完成某些任务的能力

但是，如何很好地判断效果呢？在机器学习中，我们需要定义模型的优劣程度的度量，这被称之为目标函数（objective function）。我们通常定义一个目标函数，并希望优化它到最低点。这些函数被称为损失函数（loss function，或cost function）

通常，损失函数是根据模型参数定义的，并取决于数据集。数据集中取样本用于训练，称为训练集（training dataset）。然而，在训练数据上表现良好的模型，并不一定在别的数据上有同样的性能，因此我们把其他一部分作为测试集（test set）

一个数据集通常被分成两部分：训练数据集用于拟合模型参数，测试数据集用于评估拟合的模型。然后观察模型在这两部分数据集的性能，可以类比成高考生在模考中的分数，这个分数有参考意义，但也不能确定高考分数。当一个模型在训练集上表现良好，但不能推广到测试集时，这个模型被称为过拟合（overfitting）

### 优化算法
当我们获得了一些数据源及其表示、一个模型和一个合适的损失函数，接下来就需要一种算法，它能够搜索出最佳参数，以最小化损失函数。深度学习中，大多流行的优化算法通常基于一种基本方法：梯度下降（gradient descent）。简而言之，在每个步骤中，梯度下降法都会检查每个参数，看看如果仅对该参数进行少量变动，训练集损失会朝哪个方向移动。然后，它在可以减少损失的方向上优化参数

### 模型
对数据进行一系列的训练操作，最后获得一些参数，即为模型

[^1]: Tom M. Mitchell. Machine Learning. McGraw-Hill. 1997年3月: 第2页. ISBN 0070428077